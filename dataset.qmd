---
title: "dataset"
format: pdf
---

```{r, message = FALSE}
#Import all libraries
library(rvest)
library(stringr)
library(tidyverse)
library(janitor)
library(dplyr)
```

```{r}
#create a vector for all webpages we want to scrape

urls <- c(
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_8",
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_9",
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_10",
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_11",
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_12",
  "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_series_13"
)

#Check to see if we can scrape webpages
for (i in urls){
  robotstxt::paths_allowed(urls[i])
}
```

```{r}
#Create function to scrape webpages

scrape_series <- function(url){
  
  series <- read_html(url)
  tables <- series |> html_elements("table.wikitable")
  
  df <- html_table(tables[[1]]) |> 
    janitor::remove_empty(which = "cols") 
    
  contestant <- names(df)[str_detect(names(df), "^Contestant")]
  if (!is.na(contestant)) {
    names(df)[names(df) == contestant] <- "Contestant"
  }
  
  df <- df |> 
    mutate(
      nickname = str_extract(Contestant, "'([^']+)'|\"([^\"]+)\""),
      nickname = str_remove_all(nickname, "['\"]")
    ) |>
    separate(
      Contestant, into = c("first_name", "last_name"), sep = " ", extra = "merge", remove = FALSE
    ) |>
    separate(
      Hometown, into = c("City/Town", "Country"), sep = ",", fill = "left"
    ) |>
    mutate(
      first_name = ifelse(is.na(nickname), first_name, nickname),
      last_name = ifelse(!is.na(nickname), str_extract(last_name, "[^'\" ]*$"), last_name),
      first_name = str_remove_all(first_name, "['\"]")
    ) |>
    clean_names() 
  
  return(df)
}

#https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html, for help with janitor functions
#https://medium.com/@statisticswithoutborders/r-function-of-the-week-ifelse-vs-if-else-bed37f474fca for help with ifelse()

```


```{r}
first_table <- data.frame() #Create empty data frame

#Loop over all urls and create 1 dataframe
for (i in seq_along(urls)){
  df <- scrape_series(urls[i])
  df$series <- i + 7 #Create a column with series number of each contestant
  first_table <- bind_rows(first_table, df)
}

#Credit for bind_rows: https://dplyr.tidyverse.org/reference/bind_rows.html
```


```{r}
#Add genders 
gender <- read_csv("data/genders.csv") |>
  clean_names()
first_table_and_gender <- left_join(first_table, gender, by = "contestant")
```

```{r}
#Grouping Occupations
first_table_and_gender <- first_table_and_gender |>
  mutate(
    occupation = str_replace_all(occupation, "[^A-Za-z ]", "")
  )

```




